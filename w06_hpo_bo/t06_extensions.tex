\subtitle{Extensions to Bayesian Optimization}
\begin{document}
\maketitle
	
%-----------------------------------------------------------------------
\begin{frame}{Some More Extensions We Will Discuss}
\begin{block}{Standard Bayesian optimization problems}
\begin{itemize}
    \item Continuous, smooth functions
    \item Sequential optimization
    \item Noise-free evaluations
%    \item No constraints
\end{itemize}
\end{block}
%    \pause
\begin{block}{Extensions}
\begin{itemize}
    \item Structured search spaces: categorical \& conditional hyperparameters 
%    \item Disconnected search spaces
    \item Parallel evaluations
    \item Noisy evaluations
    \item Optimization with constraints
%    \item Multi-objective Bayesian optimization
\end{itemize}
\end{block}    
\end{frame}

%\begin{frame}[c]{Categorical and Conditional Parameters}
%\framesubtitle{Introduction}
%\begin{itemize}
%    \item<+->{Our parameter configuration space $\pcs$ can possibly contain:
%    \begin{itemize}
%        \item<+->{Neural Network Architectures.}
%        \item<+->{Model-specific parameters.}
%        \item<+->{General optimization parameters.} 
%    \end{itemize}
%    }
%    \item<+->{Consider searching through such a space of parameters. Is every individual dimension of this search space-
%    \begin{itemize}
%        \item<+->{Continuous?}
%        \item<+->{Relevant?}
%    \end{itemize}
%    }
%\end{itemize}
%\end{frame}
%-----------------------------------------------------------------------
%\begin{frame}[c]{Categorical and Conditional Parameters}
%\framesubtitle{Categorical Parameters}
%\begin{itemize}
%    \item<+-> Parameters that draw values from a discrete domain instead of a real-valued domain.
%    \item<+-> Mathematically, a parameter $\hyperparam$ is a categorical parameter if $\hyperparam\in P$, where $P=\{p_1, p_2, \dots\}$ is a set of finite, discrete values.
%    \item<+-> Examples:
%    \begin{itemize}
%        \item<+-> For training a neural network, we may choose one flavor of SGD out of $\{Vanilla, \,RMSProp, \,Adam\}$.
%        \item<+-> For a layer in a Multi-Layer Perceptron, we may choose one activation function out of $\{tanh, \,sigmoid, \,relu, \,unit\}$.
%    \end{itemize}
%    \item<+-> Categorical parameters present a challenge: inferring gradients is not possible for unordered categories!
%    \item<+-> Another challenge: Each individual category, or possible value of a categorical parameter, contributes to the curse of dimensionality in naive search approaches.
%\end{itemize}
%\end{frame}
%%-----------------------------------------------------------------------
%\begin{frame}[c]{Categorical and Conditional Parameters}
%\framesubtitle{Hamming Distance Kernel}
%\begin{center}
%Placeholder - Describe Hamming Distance Kernel from Frank's PhD thesis, include visualization
%\end{center}
%\end{frame}
%-----------------------------------------------------------------------
%\begin{frame}[c]{Categorical and Conditional Parameters}
%\framesubtitle{Conditional Parameters}
%\begin{itemize}
%    \item<+-> Some parameters in the search space are only relevant in the context of specific values of other parameters.
%    \item<+-> For example, if we are training a Neural Network using SGD, the momentum parameter is only relevant when using a flavour of SGD that supports it, such as Adam,
%    \item<+-> Such parameters can be used to define conditional dependencies between parameters
%    \item<+-> These dependencies define active/inactive sub-spaces within the search space
%    \item<+-> Conditional parameters are most recognizable in the context of categorical parameters, but they need not be categorical
%    \item<+-> Similar to categorical parameters, inferring gradients is not possible due to the presence of active/inactive sub-spaces
%\end{itemize}
%\end{frame}
%-----------------------------------------------------------------------
% \begin{frame}[c]{Categorical and Conditional Hyperparameters}
% \framesubtitle{Structured Search Spaces}
% \begin{itemize}
%     \item<+-> In HPO, we have prior knowledge about when some hyperparameters in the search space are completely irrelevant
%     \item<+-> Naively searching over the entire search space while disregarding any conditional dependencies is inefficient
%     \item<+-> We can impose a structure over the search space with the help of conditional dependencies between the various parameters to speed-up and optimize the HPO task
% \end{itemize}
% \end{frame}
%-----------------------------------------------------------------------
\begin{frame}[c]{Structured Search Spaces: Categorical \&  Conditional Hyperparameters}
\begin{center}
    \includegraphics[width=.9\linewidth, height=0.9\textheight, keepaspectratio=true]{images/categ_cond_params/Conditional Parameters AutoML Book.png}
    \newline
    Example of a structured search space (Source: Figure 5.1 of the \lit{\href{https://www.automl.org/wp-content/uploads/2019/05/AutoML_Book.pdf}{AutoML book}})
\end{center}
\end{frame}
%-----------------------------------------------------------------------
\begin{frame}[c]{Structured Search Spaces: Categorical Hyperparameters}

\begin{columns}[T]
\column{0.65\textwidth}

\medskip
Properties of categorical hyperparameters:
\myit{
    \item \alert{Finite, discrete} set of values
    \item \alert{No natural order} between values 
    \item Potentially different distances between values
}


\column{0.35\textwidth}
\vspace{0.5cm}
\includegraphics[width=1\textwidth]{images/categ_cond_params/categorical.png}
%
\end{columns}

\pause
\vspace*{-0.4cm}
This has to be taken into account by the surrogate model:
%
\begin{itemize}
    \item Random Forests \alert{natively} handle categorical inputs \lit{\href{https://ml.informatik.uni-freiburg.de/papers/11-LION5-SMAC.pdf}{Hutter et al, 2011}}
    \item \emph{One-hot} encoding provides a simple general solution
    \item Gaussian Processes can use a (weighted) \alert{Hamming Distance Kernel} \lit{\href{https://www.cs.ubc.ca/~hutter/papers/Hutter09PhD.pdf}{Hutter 2009}}:
\vspace*{-0.2cm}
\begin{equation*}
    \kernel_{\theta}(\conf_i, \conf_j) = \exp{\sum_{l=1}^d (-\theta \cdot \delta(\hyperparam_{i,l} \neq \hyperparam_{j,l}))}
\end{equation*}

\vspace*{-0.2cm}
\item Neural networks can learn \alert{entity embeddings} for categorical inputs \lit{\href{https://arxiv.org/pdf/1604.06737.pdf}{Guc et al. 2016}}
\end{itemize}
%
\end{frame}
%-----------------------------------------------------------------------
\begin{frame}[c]{Structured Search Spaces: Conditional Hyperparameters}


\begin{columns}[T]
\column{0.65\textwidth}
\vspace*{0.2cm}
Conditional hyperparameters:
\myit{
    \item Are \alert{only relevant if} certain other hyperparameters take on certain values
    \item \alert{Should be ignored} by the model \alert{if not active}
} 

\column{0.35\textwidth}
\vspace{0.5cm}
\includegraphics[width=1\textwidth]{images/categ_cond_params/conditional.png}
%
\end{columns}

\pause 
\vspace*{-0.2cm}
Modelling conditional hyperparameters:
\myit{
    \item Setting the values for inactive hyperparameter to a specific value (e.g. $0$)
    \item Random Forests \lit{\href{https://ml.informatik.uni-freiburg.de/papers/11-LION5-SMAC.pdf}{Hutter et al. 2011}} and Tree Parzen Estimators \lit{\href{http://papers.nips.cc/paper/4443-algorithms-for-hyper}{Bergstra et al. 2011}} can \alert{natively} handle conditional inputs
    \item There exist \alert{several kernels for Gaussian Processes} to handle conditional inputs \lit{\href{https://arxiv.org/abs/1310.5738}{Hutter et al. 2013}} \lit{\href{https://www.etsmtl.ca/Unites-de-recherche/LIVIA/Recherche-et-innovation/Publications/Publications-2017/Levesque_ijcnn_2017.pdf}{LÃ©vesque et al. 2017}} \lit{\href{http://proceedings.mlr.press/v70/jenatton17a.html}{Jenatton et al. 2017}} 
}
%
\pause
\vspace{0.4cm}
Overall, structured search spaces are \alert{still an active research topic} and far from solved
\end{frame}


\begin{frame}[c]{Parallel Bayesian Optimization: Multi-point Acquisition Functions}

\myit{
    \item Often, we have many parallel compute units
    \item How should these be exploited in (the typically inherently sequential) Bayesian optimization?
\medskip
\pause
    \item To select a batch of $q$ points in parallel, we need to compute the multi-point acquisition function.
    E.g., for expected improvement:
    \begin{equation*}
        q\text{-EI}(\conf_{1, \dots, q}) = \E \left[ \cost(\incumbent) - \min_{i=1, \dots, q} \surro(\conf_i) \right]
    \end{equation*}
\pause
\medskip
    \item For EI and KG, this requires \emph{expensive-to-compute} q-dimensional Gaussian cumulative distributions \lit{\href{https://hal.archives-ouvertes.fr/hal-00260579/document}{Ginsbourger et al. 2007}}, \lit{\href{https://arxiv.org/pdf/1606.04414v4.pdf}{Wu et al. 2018}}, \lit{\href{https://arxiv.org/pdf/1602.05149.pdf}{Wang et al. 2019}}
    \pause
    \item Nevertheless, multi-point acquisition functions can be optimized efficiently with gradient descent via the reparameterization trick \lit{\href{https://papers.nips.cc/paper/8194-maximizing-acquisition-functions-for-bayesian-optimization}{Wilson et al. 2018}}
}
\end{frame}
%----------------------------------------------------------------------
\begin{frame}[c]{Asynchronous Parallel Bayesian Optimization with Pending Evaluations}

\myit{
    \item In practice, typically, not all function evaluations take the same amount of time
    \myit{
        \item Thus, we need to select \alert{some new points} while we're still waiting for \alert{pending evaluations} at other points
    }
\pause
\bigskip
%
    \item Simple solution: \alert{hallucinate observations for pending evaluations}, and use otherwise standard methods:
    \pause
    \myit{
        \item \alert{Constant Liar}: Choose a fixed value (constant) \lit{\href{http://www.cs.ubc.ca/labs/beta/EARG/stack/2010_CI_Ginsbourger-ParallelKriging.pdf}{Ginsbourger et al. 2010}}
\smallskip
\item \alert{Kriging Believer}: Use the current mean prediction (belief)  \lit{\href{http://www.cs.ubc.ca/labs/beta/EARG/stack/2010_CI_Ginsbourger-ParallelKriging.pdf}{Ginsbourger et al. 2010}}
\smallskip
\item \alert{Monte Carlo Fantasies} 
        \pause
        \myit{
            \item Sample pending evaluations from the model
            \item Update copy of the model with these samples
            \item Compute acquisition function under each updated copy 
            \item Define acquisition function as an average over these sampled acquisition functions
%            (fantasies, more details on the next slide).
        }
    }
}

\end{frame}
%----------------------------------------------------------------------
\iffalse
\myframetop{Asynchronous Parallel Bayesian Optimization with Pending Evaluations}{
    %
    Assume we have observed data $\left\{ \left\langle \bonextsample, \bonextobs \right\rangle \right\}^{N}_{\bocount = 1}$ and $J$ evaluations are pending $\left \{\conf_{j} \right \}^{J}_{j = 1}$. We can compute the expected mean function using the following integral: \pause
    \begin{equation*}
    \begin{aligned}
        \Bar{\acq} \left( \conf; \left\{ \left\langle \bonextsample, \bonextobs \right\rangle \right\}^{N}_{\bocount = 1}, \left \{\conf_{j} \right \}^{J}_{j = 1} \right) =  \pause
        \int_{\mathbb{R}^J}  \acq \left( \conf; \left\{ \left\langle \bonextsample, \bonextobs \right\rangle \right\}^{N}_{\bocount = 1}, \left \{ \left\langle \conf_j, \obs_j \right\rangle \right \}^{J}_{j=1} \right) \\
        p( \{ \obs_j \}^{J}_{j = 1}  \rvert \{ \conf_j \}^{J}_{j = 1}, \left \left\{ \left\langle \bonextsample, \bonextobs \right\rangle \right\}^{N}_{\bocount = 1} )d\obs_1 \dots d\obs_J
    \end{aligned}
    \end{equation*}
    %
    \vspace{-0.8cm}
    \begin{columns}
    \column{0.6\textwidth}
    \only<4->{
    \begin{enumerate}
        \only<4->{\item Evaluated observations: $\left \{\conf_1, \conf_3, \conf_4 \right \}$, pending: $\left \{\conf_2, \conf_5 \right \}$.}
        \only<5->{\item Fit a model for each possible realization of $\left \{\cost(\conf_2), \cost(\conf_5) \right \}$.}
        \only<6->{\item Calculate acquisition function for each model.}
        \only<7->{\item Integrate all acquisition functions over $\conf$.}
    \end{enumerate}
    }
    
    \column{0.4\textwidth}
        \only<4-5>{
        \begin{figure}
            \centering
            \includegraphics[width=0.8\textwidth]{images/parallel/parallel_a.jpg}
        \end{figure}
        }
        \only<6>{
        \begin{figure}
            \centering
            \includegraphics[width=0.8\textwidth]{images/parallel/parallel_b.jpg}
        \end{figure}
        }
        \only<7->{
        \begin{figure}
            \centering
            \includegraphics[width=0.8\textwidth]{images/parallel/parallel_c.jpg}
        \end{figure}
        }
    \end{columns}
    
    \source{\href{https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf}{Snoek et al. 2012}}

\vspace*{-0.4cm}
% \notefh{As I mentioned in class, I think the EI plot is wrong; it needs to be zero at the points where fantasies are being evaluated. Can you code this up and make a proper plot this week? Otherwise, I would drop this slide.}

}
\fi
%
%\begin{frame}
%\begin{itemize}
%    \item <+-> Utilize tractable properties of GP to get Monte Carlo estimates of %acquisition function under different results from pending function evaluations. \pause
%    \item <+-> Consider the case where $N$ evaluations have completed, with data $\left \{\bonextsample, \bonextobs \right \}^{N}_{\bocount = 1}$ and $J$ evaluations are pending $\left \{\conf_{j} \right \}^{J}_{j = 1}$: \pause
%    \begin{equation*}
%        \begin{aligned}
%            \hat{\acq} ( \conf; \left \{ \bonextsample, \bonextobs \right \}, \left \{ \conf_j \right \} ) =  \pause
%            \int_{\mathbb{R}^J}  \pause \acq ( \conf; \left \{ \bonextsample, %\bonextobs \right \}, \left \{ \conf_j, \obs_j \right \} ) \\  \pause
%            p(\left \{ \obs_j \right \}^{J}_{j = 1}  \rvert \left \{ \conf_j \right \}^{J}_{j = 1}, \left \{ \bonextsample, \bonextobs \right \}^{N}_{\bocount=1} )d\obs_1 \dots d\obs_J
%        \end{aligned}
%    \end{equation*}
%\end{itemize}

%\source{\href{https://csc2541-f17.github.io/}{Scalable and Flexible Models of Uncertainty, University of Toronto}}

%\end{frame}
%-----------------------------------------------------------------------
\begin{frame}[c]{Noisy Evaluations}

    \begin{columns}[T]
    
        \column{0.6\textwidth}
    
        \myit{
            \item The probabilistic model natively supports Gaussian noise
            \myit{
                \item A good hyperprior for the noise variance might be needed to robustly determine the right size of the noise
                \item Noise that is not Gaussian (and not Student t \lit{\href{https://www.asc.ohio-state.edu/santner.1/TJS-BJW-WIN/master-driver.pdf}{Santner et al, 2014}}) would require approximations 
            }
        }
    
        \column{0.4\textwidth}
        \includegraphics[width=\textwidth]{images/extensions/BO_Loop_Noisy3.png}
        
    \end{columns}
    %        Given noisy evaluations, GP regression proceeds similarly to the noiseless case by adding the variance to the diagonal of the covariance matrix.
    %        \vspace{-0.2cm}
    %        \item KG and ES directly handle noisy function evaluations~\lit{\href{https://arxiv.org/abs/1807.02811}{Frazier 2018}}.
    %        \vspace{-0.2cm}
    
\pause
\bigskip
    \myit{
        \item The acquisition function might need adaptation
        \myit{
            \item LBC, TS, ES, and KG, are not affected
            \item PI and EI are based on an the cost $\cost_{inc}$ of the incumbent; it is unclear how to compute this
            \begin{itemize}
                \item Uncertainty about which point is the current incumbent 
                \item Uncertainty about the costs $\cost(\conf_i)$.
                \item \alert{Noisy Expected Improvement}~\lit{\href{https://arxiv.org/abs/1706.07094}{Letham et al. 2019}} extends  regular EI by integrating over the predictive posterior of the model using Monte Carlo
            \end{itemize}
        }
    %        Computing EI with observation noise is challenging:
    %        \vspace{-0.2cm}
}
    

%\begin{itemize}
%    \item Noisy Expected Improvement~\lit{\href{https://arxiv.org/abs/1706.07094}{Letham et al. 2019}} extends the regular Expected Improvement by integrating over the predictive posterior of the model:
%    % There's an additional paper by Gramacy and Lee from 2011 which does a more complicated treatment of noise in EI
%    \begin{equation*}
%        \acq_{NEI}(\conf|\dataset)=\int_{\surro}\acq_{EI}(\conf|\surro)p(\surro|\dataset)\text{d}\surro
%    \end{equation*}
%    \vspace{-0.2cm}
%    \begin{itemize}
%        \item Compute with Monte Carlo Integration.
%        \item Each sample from the model posterior has its own incumbent $\incumbent[\bocount-1]$.
%    \end{itemize}
%    \end{itemize}
\end{frame}

%----------------------------------------------------------------------

\begin{frame}[c]{Bayesian Optimization with Constraints}

\begin{columns}[T]

\column{0.6\textwidth}

Three types of constraints 
% \notefh{Four? There are 3 listed here. Also, from the description here I don't see a difference between unknown and hidden constraints, just that in the unknown case you're trying to model them!? @Matthias: this might be most efficient to discuss on the phone.}
\begin{small}
\begin{enumerate}
    \item Known constraints: can be accounted for when optimizing $\acq$
    %\item Policy constraints: function value is observed, but deemed forbidden~\lit{\href{https://www.soe.ucsc.edu/sites/default/files/technical-reports/UCSC-SOE-10-10.pdf}{Lee and Gramacy 2010}}
    \item Hidden constraints: no function value is observed due to a failed function evaluation~\lit{\href{https://www.soe.ucsc.edu/sites/default/files/technical-reports/UCSC-SOE-10-10.pdf}{Lee and Gramacy 2010}}
    \item Unknown constraints: there's an additional, but unknown constraint function, for example the memory used, which can be observed and modeled
\end{enumerate}
\end{small}

\column{0.4\textwidth}
\includegraphics[width=0.9\textwidth]{images/extensions/notebooks_constrained_bo_4_0.png}\\
	\footnotesize{Hidden constraints. Image source: \lit{\href{https://gpflowopt.readthedocs.io/en/latest/notebooks/constrained_bo.html}{GPFlowOpt Tutorial, Apache 2 License}}}

\end{columns}

Most general solution: \emph{Expected Constrained Improvement}~\lit{\href{https://www.soe.ucsc.edu/sites/default/files/technical-reports/UCSC-SOE-10-10.pdf}{Lee and Gramacy 2010}}:
\vspace{-0.1cm}
\begin{equation}
    ECI(\conf) = EI(\conf)h(\conf),
\end{equation}
\vspace{-0.1cm}
where $h(\conf)$ is the probability that $\conf$ is a valid configuration.

\vspace{0.1cm}
Further literature in \lit{\href{https://arxiv.org/abs/1807.02811}{Frazier 2018}} and \lit{\href{https://link.springer.com/chapter/10.1007/978-3-030-05318-5_1}{Feurer and Hutter 2019}}.

\end{frame}
%----------------------------------------------------------------------
\begin{frame}[c]{Further extensions}
\framesubtitle{Even more extensions}
Bayesian optimization has been extended to numerous scenarios:
\begin{itemize}
    \item Multi-task, Multi-fidelity and Meta-learning $\rightarrow$ separate lecture
    \item Multi-objective Bayesian optimization $\rightarrow$ separate lecture
    \item Bayesian optimization with safety guarantees~\lit{\href{http://proceedings.mlr.press/v37/sui15.pdf}{Sui et al. 2015}}
    \item Directly optimizing for ensemble performance~\lit{\href{http://auai.org/uai2016/proceedings/papers/73.pdf}{LÃ©vesque et al. 2016}}
    \item Combination with local search methods~\lit{\href{https://www.researchgate.net/publication/241216681_Bayesian_Guided_Pattern_Search_for_Robust_Local_Optimization}{Taddy et al. 2009}}~\lit{\href{https://papers.nips.cc/paper/8788-scalable-global-optimization-via-local-bayesian-optimization.pdf}{Eriksson et al. 2019}}
    \item Optimization of arbitrary spaces that can be described by a kernel (e.g., neural network architectures~\lit{\href{https://papers.nips.cc/paper/7472-neural-architecture-search-with-bayesian-optimisation-and-optimal-transport.pdf}{Kandasamy et al. 2018}} or 
    %a latent embedding, such as
    molecules~\lit{\href{https://arxiv.org/abs/1709.05501}{Griffiths et al. 2017}})
    \item Many more (too many to mention)
\end{itemize}
  
\end{frame}
%-----------------------------------------------------------------------
\begin{frame}[c]{Questions to Answer for Yourself / Discuss with Friends}

\begin{itemize}
% Categorical and Conditional
\item \alert{Discussion.} What would happen if you treat a categorical hyperparameter as continuous (e.g., $\{A, B, C\}$ as $\{0, 0.5, 1\}$), in Bayesian optimization using a Gaussian Process?
\medskip
% Parallel
\item \alert{Repetition.} Which methods can you use to impute values for outstanding evaluations? What are advantages and disadvantages of each method?
\medskip
% Noise & Constrained
\item \alert{Discussion.} What are worst case scenarios that could happen if you ignore the noise during Bayesian optimization?
% Further
\end{itemize}
\end{frame}

%\end{document}
